
* Global settings:
Some of these may be environment-dependent, e.g. NODE_ID, others are global settings that change run behaviour (e.g. SCHEDULING_MODE) or even results (SAMPLING_TRAFO)
** Environment only
- SBATCH_INDEX :: set while calling sbatch, see *setup.recipe*.
** Environment AND R setting
- NODEDIR :: node-local directory. Set by *runscript.sh* to form =PWD/xx/nodename/work=, where =xx= is the first two characters of =md5sum $nodename=.
  - WORKDIR :: base directory from which to work. Set by *runscript.sh* to a subdirectory of NODEDIR, depending on SLURM_STEP_ID
    - OUTPUTDIR :: directory where the output is written. set using *rbn.setOutputDir()* in *constants.R* to a subdir in WORKDIR. Should be called before each new output file is opened.
  - WATCHFILE :: watchdog file. Set by *runscript.sh* to a file identified by PID in NODEDIR
- MUC_R_HOME :: base directory of this repository, has subdirectories =scripts/=, =R/=. Set/inferred by *runscript.sh* and others.
** R setting only
- DATADIR :: directory where data files are stored, set by *constants.R* to =MUC_R_HOME/data=
  - DATA_TABLE :: filename of data info csv. set by *constants.R*
  - DATA_TABLE_OPTS :: options to be given to =read.csv= when reading DATA_TABLE. set by *constants.R*
- SEARCHSPACE_TABLE :: filename of search space csv. set by *constants.R*
- SEARCHSPACE_TABLE_OPTS :: options to be given to =read.csv= when reading SEARCHSPACE_TABLE. set by *constants.R*
- RUN_ID ::  [integer] number of the run. Between 0 and 2^31-1 inclusive. used for seeding / indexing into table. Set depending on SCHEDULING_MODE.
- LEARNER :: [character(1)] learner name to be evaluated in this instance. Taken from command line.
- DATASET :: [character(1)] dataset name to be evaluated in this instance. Taken from command line.

- SCHEDULING_MODE :: [string] "perseed", "perparam", "percpu": "perseed": one job per seed value. "perparam": one job per param string (given in command line). "whole": one job per CPU which loops through seeds itself. set while calling sbatch, see *setup.recipe*.
  - SEED_STEPSIZE :: if SCHEDULING_MODE is "percpu": how much to increase RUN_ID each execution. Should be roughly NUMBER_OF_CPUS / ( NUMBER_OF_TASKS * NUMBER_OF_LEARNERS )
  - SEED_OFFSET :: if SCHEDULING_MODE is "percpu": at what RUN_ID to start at first; should be between 0 and SEED_STEPSIZE.
  - SEED_INIT_ID ::  if SCHEDULING_MODE is "percpu": at what RUN_ID to start the current loop; used to communicate from =.sh= to =.R=.
- SUPERRATE :: [numeric 0..1] fraction of evaluation points that have supererogatory evaluations
- SAMPLING_TRAFO :: "none", "default", "default+norm"
  - "none" :: transformations given in paramspace csv are not performed (although the given parameter limits are transformed)
  - "default" :: transformations as given in paramspace csv
  - "norm" :: transformation as given, prepended by an inverse error function; parameter bounds as given are instead the inflection points of the normal distribution (i.e. each 1 std-dev from center)
- RESAMPLINGTIMEOUTS :: [numeric] seconds to wait for each resampling. Violating the time constraint kills the R session if the watchdog is running.
- WATCHFILE :: [character(1)] path to file that is watched by the watchdog script


* Directory structure
- data
  input arguments are in file DATADIR/INPUTS, a *single space* separated file with columns <LEARNER> <TASK> <POINT_STRING>. LEARNER changes the fastest, then TASK, then POINT_STRING changes slowest (i.e. LEARNER is the inner loop)
* Scripts
- scripts
  - scripts/runscript.sh :: to be called by =srun=, takes important


* scheduling
** "percpu" scheduling
 - Have a directory hierarchy that maps from "task, learner, INIT_ID" to the path where the checkpoint file is written
 - run each srun in the form =(while true ; do srun TASK LEARNER INIT_ID ; done) &=
 - srun call looks up directory, looks up checkpoint, copies checkpoint to its own directory, overwrites lookup file, runs
** "perseed" scheduling
 - sequentially go along seeds, learners, tasks
 - executed using GNU Parallel
** "perparam" scheduling
 - parameters are in a text file
 - executed using GNU Parallel


